"""
Groq LLM service for AI content generation.
Uses langchain-groq integration.
"""
import json
from typing import Dict, List, Any, Optional

from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

from app.config import settings
from app.utils.logging import get_logger

logger = get_logger(__name__)


class GroqService:
    """Service for LLM interactions via Groq."""

    def __init__(self):
        self.llm = ChatGroq(
            temperature=settings.groq_temperature,
            model=settings.groq_model,
            max_tokens=settings.groq_max_tokens
        )
    
    async def generate_script(self, topic: str) -> Dict[str, Any]:
        """
        Generate a video script from a topic.

        Returns JSON: {scenese: [{speaker, line, duration}]}
        """
        prompt = ChatPromptTemplate.from_messages({
            ("system", """
            You are an expert YouTube scriptwriter. Create an engaging, dynamic script based on the user's topic.
            Follow these rules:
            1. Use 2-4 distinct speakers (e.g., specific names or generic 'Host', 'Expert', 'Narrator'. But not "I", or "Me").
            2. Keep lines concise and conversational.
            3. Include estimated duration for each line in seconds.
            4. Structure the output as valid JSON only.
            5. If the user specifies a target duration, aim for that length. 
               Otherwise, create a 5-10 minute video (more content is better).
            6. IMPORTANT: Generate COMPLETE scenes. Every scene MUST have all three fields: "speaker", "line", and "duration".
            
            Output format:
            {{
                "scenes": [
                    {{
                        "speaker": "Host",
                        "line": "Welcome back to the channel!",
                        "duration": 3.0
                    }}
                ]
            }}
            """),
            ("human", "{topic}")
        })

        chain = prompt | self.llm | JsonOutputParser()

        try:
            logger.info("Generating script", topic=topic)
            result = await chain.ainvoke({"topic": topic})
            return result
        except Exception as e:
            logger.error("Script generation failed", error=str(e))
            raise

    async def generate_metadata(
        self,
        script_content: str,
        context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Generate YouTube title, description, and tags.
        """
        prompt = ChatPromptTemplate.from_messages([
            ("system", """
            You are a YouTube SEO expert. Generate optimized metadata for a video based on its script.
            
            Requirements:
            1. Title: Click-worthy, includes keywords, max 100 chars.
            2. Description: Engaging summary, 3 paragraphs.
            3. Tags: 10-15 high-ranking keywords as an array of strings.
            4. Category ID: Choose the best numeric category ID (22=People & Blogs, 27=Education, 28=Tech, etc).
            
            Output format:
            {{
                "title": "Unbelievable AI Breakthroughs Explained",'
                "description": "In this video, we explore...",
                "tags": ["AI", "Tech", "Future"],
                "category_id": "28"
            }}
            """),
            ("human", "Script: {script}\n\nAdditional Context: {context}")
        ])

        chain = prompt | self.llm | JsonOutputParser()

        try:
            # Flatten script to text for prompt
            script_text = script_content
            if isinstance(script_content, dict) or isinstance(script_content, list):
                script_text = json.dumps(script_content)

            logger.info("Generating metadata")
            result = await chain.ainvoke({
                "script": script_text[:8000],
                "context": context or "None"
            })
            return result
        except Exception as e:
            logger.error("Metadata generation failed", error=str(e))
            # Return fallback structure on failure
            return {
                "title": "Generated Video",
                "description": "Video generated by Faceless YouTube Factory.",
                "tags": ["AI", "Automation"],
                "category_id": "22"
            }

    async def generate_raw(self, prompt: str) -> str:
        """
        Generate raw text response from a prompt.
        
        Used for flexible tasks like voice casting where we need
        more control over parsing.
        """
        try:
            logger.info("Generating raw LLM response")
            response = await self.llm.ainvoke(prompt)
            return response.content
        except Exception as e:
            logger.error("Raw generation failed", error=str(e))
            raise


# Singleton instance
groq_service = GroqService()